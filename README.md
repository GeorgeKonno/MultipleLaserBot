# MutipleLaserBot!
20世纪以来，室内外自主移动机器人飞速发展，并以此为契机出现了大量的创业型公司。
得益于ROS这个开发体系的日渐完善，能够被直接调用的开源机器人导航及建图算法也越来越多。
就SLAM而言，包括激光，视觉或者语义在内的算法框架不下五十种。
大多数的研发人员都会面临一个致命的问题。
该怎么选？
在这个公司的特定应用场景中，到底是激光还是视觉，还是两者融合的算法更具优势？
而且，往往在实际工程项目中，困扰大家的问题还包括主板开发性能的限制，这套算法是否能够达到实效的双重要求。
笔者自19年入行自主移动型机器人，一直以激光SLAM和导航的开发为主。
而在笔者想要融合视觉的时候，发现当下的SLAM框架具有很大的割裂性。
笔者认为，任何一种SLAM算法，只不过是一个可被调用的method，急需要一种更庞大的框架，提供给研发人员进行快速高效的多传感器的尝试。
因为最近有在做一个多线激光雷达的配送机器人项目，所以正好借这个机会，来实现这个庞大的框架。
本项目大部分算法来源于开源包，也有一部分引用论文的实现和改进，例如：现在非常火热的基于语义的点云匹配，以及submap-submap的新型cartographer等。
一部分对于原始包的优化，读者可以根据commit的记录追溯。
项目持续开发，结束时间不确定，如有发现bug或者有更多的方案，可以提交pr。
[Screenshot from 2022-04-21 10-44-38](https://user-images.githubusercontent.com/61740700/164361408-3b282c94-3882-46d2-9604-bf33fbad439a.png)
